{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype for Getting Text from Azure for Checkbox1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "from PIL import Image\n",
    "#import keys for azure\n",
    "import keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keys and paths\n",
    "subscription_key = keys.COMPUTER_VISION_SUBSCRIPTION_KEY\n",
    "endpoint = keys.COMPUTER_VISION_ENDPOINT\n",
    "sub_images_path = \"images/sub_images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#api url\n",
    "text_recognition_url = endpoint + \"/vision/v3.0-preview/read/analyze\"\n",
    "\n",
    "# Set the langauge that you want to recognize. The value can be \"en\" for English, and \"es\" for Spanish\n",
    "language = \"en\"\n",
    "\n",
    "headers = {'Ocp-Apim-Subscription-Key': subscription_key,\n",
    "          \"Content-Type\": \"application/octet-stream\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of sub images\n",
    "sub_images = [\"Name\",\"DOB\",\"Unique_id\",\"Date\",\"Staff\",\"UnitsShown\",\"LotNum\",\"ExpDate\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_read(sub_images):    \n",
    "    \n",
    "    #initialize dictionary\n",
    "    returned_data = {}\n",
    "    \n",
    "    #loop through sub images and call api\n",
    "    for sub_image in sub_images:\n",
    "        #intialize dictionary\n",
    "        returned_data[sub_image] = {}\n",
    "\n",
    "        image_path = sub_images_path + sub_image + \".jpeg\"\n",
    "        image_data = open(image_path, \"rb\").read()\n",
    "\n",
    "        #call api\n",
    "        response = requests.post(\n",
    "            text_recognition_url, headers = headers,params = {'language': language}, data=image_data)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Extracting text requires two API calls: One call to submit the\n",
    "        # image for processing, the other to retrieve the text found in the image.\n",
    "\n",
    "        # Holds the URI used to retrieve the recognized text.\n",
    "        operation_url = response.headers[\"Operation-Location\"]\n",
    "\n",
    "        # The recognized text isn't immediately available, so poll to wait for completion.\n",
    "        analysis = {}\n",
    "        poll = True\n",
    "        while (poll):\n",
    "            response_final = requests.get(\n",
    "                response.headers[\"Operation-Location\"], headers=headers)\n",
    "            analysis = response_final.json()\n",
    "\n",
    "            #time.sleep(1)\n",
    "            if (\"analyzeResult\" in analysis):\n",
    "                poll = False\n",
    "            if (\"status\" in analysis and analysis['status'] == 'failed'):\n",
    "                poll = False\n",
    "                \n",
    "        #extract text and confidence from the returned api call        \n",
    "        lines = analysis[\"analyzeResult\"]['readResults'][0]['lines']\n",
    "        text = \"\"\n",
    "        for line in lines:\n",
    "            if text == \"\":\n",
    "                text = line[\"text\"]\n",
    "            else:\n",
    "                text = text + \" \" + line[\"text\"]\n",
    "\n",
    "            for i,word in enumerate(line[\"words\"]):\n",
    "                returned_data[sub_image][\"confidence_\"+ str(i)] = word[\"confidence\"]\n",
    "\n",
    "        returned_data[sub_image][\"text\"] = text\n",
    "        \n",
    "    return returned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': {'confidence_0': 0.958, 'confidence_1': 0.633, 'text': 'Seth Mcfarlane'}, 'DOB': {'confidence_0': 0.445, 'text': '8/19/54'}, 'Unique_id': {'confidence_0': 0.893, 'confidence_1': 0.603, 'text': 'TL 6428'}, 'Date': {'confidence_0': 0.488, 'confidence_1': 0.487, 'text': '1 12/120'}, 'Staff': {'confidence_0': 0.958, 'confidence_1': 0.762, 'text': 'Seth Mcfarlane'}, 'UnitsShown': {'text': ''}, 'LotNum': {'confidence_0': 0.253, 'text': 'ject. Mcfarlane'}, 'ExpDate': {'text': ''}}\n"
     ]
    }
   ],
   "source": [
    "data = call_read(sub_images)\n",
    "print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
